terms_definitions = {
    "Operating System": "Your system has to help potential reviewers understand what, exactly, you are building.",
    "System Features": "This section should help potential reviewers understand the specific feature capabilities of the system and how the system's evaluation in its impact assessment relates to existing systems or features.",
    "Indirect Stakeholders": "An indirect stakeholder in the context of the AI Act refers to individuals, groups, or entities who are not directly involved in the development or deployment of an AI system but may be affected by its use or outcomes, such as bystanders, society at large, or third-party organizations.",
    "Impact Assessment": "An impact assessment in the context of the AI Act refers to a systematic evaluation of the potential risks, benefits, and societal impacts of an AI system, particularly focusing on its effects on fundamental rights, safety, and ethical considerations, to ensure compliance with regulatory requirements.",
    "Direct Stakeholder User": "Direct stakeholders are those involved in the company's day-to-day activities.",
    "Potential Benefits": "The AI Act ensures trustworthy AI development by promoting transparency, fairness, and accountability, mitigating risks like bias and privacy violations, while fostering innovation and legal certainty for businesses and users across the EU.",
    "Potential Harm": "A common thread among most of these frameworks is that incident definitions they use often focus on potential harm, actual harm, or both (OECD, 2023).",
    "Data-Cleaning": "Where relevant, the data requirements include datasheets describing the training methodologies, techniques, and training data sets used, including a general description of these data sets, information about their provenance, scope, and main characteristics; how the data was obtained and selected; and labeling procedures (e.g., for supervised learning).",
    "Bias Detection": "The process of identifying, addressing, and mitigating biases within workplaces or any other setting where human judgment is exercised. These biases can manifest in various forms, such as gender bias, racial bias, age bias, or even cognitive bias.",
    "Back Up Data": "A technology service that implements the behavior of a software tool that creates a copy of important data or information to ensure that it can be recovered in case of data loss, corruption, or system failure.",
    "Marginalized Groups": "Different groups of people within a given culture, context, and history at risk of being subjected to multiple discrimination due to the interplay of different personal characteristics or grounds, such as sex, gender, age, ethnicity, religion or belief, health status, disability, sexual orientation, gender identity, education or income, or living in various geographic localities.",
    "AI Audits": "An audit refers to a review of the AI system to assess the algorithms, data, design, and models. Therefore, auditing with external and internal auditors helps recognize AI-based systems' trustworthiness.",
    "Mitigation of Risk": "The AI Act mitigates risks by enforcing transparency, bias prevention, human oversight, cybersecurity, and regulatory compliance, ensuring AI systems operate safely, fairly, and accountably.",
    "Human on the Loop": "Intelligent systems are designed to augment or enhance humans, serving as tools to be wielded through human interaction.",
    "Political Opinions": "Personal data revealing racial or ethnic origin, political opinions, religious or philosophical beliefs, or trade union membership shall be prohibited from processing unless specific conditions apply.",
    "Anonymized Data": "The process of irreversibly altering personal data so that individuals can no longer be identified, directly or indirectly, in any way.",
    "Pseudo-Anonymized Data": "Pseudonymization means the processing of personal data in such a manner that the personal data can no longer be attributed to a specific data subject without the use of additional information, provided that such additional information is kept separately and is subject to technical and organizational measures to ensure that the personal data are not attributed to an identified or identifiable natural person.",
    "Risk": "The combination of the probability of an occurrence of harm and the severity of that harm.",
    "Operator": "A provider, product manufacturer, deployer, authorized representative, importer, or distributor.",
    "Deployers": "Organizations using AI in decision-making, such as businesses, public sector institutions, and other organizations that integrate AI into their processes.",
    "Misuse": "Minimal risk: Most AI systems, such as AI-enabled recommender systems and spam filters, fall into this category. These systems face no obligations under the AI Act due to their minimal risk to citizens' rights and safety. Companies can voluntarily adopt additional codes of conduct.",
    "Internal Audits": "Internal stakeholders involve engineering and security teams on the technical side and business leaders engaged with the AI strategy.",
    "External Audits": "AI not only integrates a variety of enterprise technologies but also involves multiple internal teams and external third parties."
}


