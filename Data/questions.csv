ID,Question,Section,Example,Information,Resources
1,Were any data-cleaning steps applied before using the datasets?, System Information,e.g. Eliminate Duplicate or Irrelevant Data Correct Structural Errors Filter Outliers Address Missing Data Validate and Quality-Check, Data and Data Governance Requires that datasets used for training validation and testing be relevant representative free of errors and complete.,Annex IV Article 10 point 2
2,Are there any restrictions on the use of the datasets due to licensing or data protection laws?,System Information,Using personal data (e.g. names email addresses or health records) without explicit consent from individuals violates GDPR. For instance training an AI system on healthcare data without patient consent is illegal.,The EU AI Act prohibits certain uses of artificial intelligence (AI). These include AI systems that manipulate people's decisions or exploit their vulnerabilities systems that evaluate or classify people based on their social behavior or personal traits and systems that predict a person's risk of committing a crime.,Article 5 â€“ Prohibited AI Practices Article 6 Annex 5
3,Is your system a General Purpose AI model?,System Information,,,
4,Is your system capable of adapting to new tasks autonomously?,System Information,,,
5,Does your system fall within any of the following categories?,System Information,,,
6,What are the known limitations of the system?,System Information,,,
7,Does the system provide explanations or justifications for its outputs?,System Information,,,
8,Has the system been tested or validated for its intended use cases?,System Information,,,
9,What methodologies were used for testing or validating the system?,System Information,,,
10,What were the results of the testing or validation ?,System Information,,,
11,"Does the system require real-time decision-making, or does it operate in a batch-processing manner?",System Information,,,
12,What are the intended uses of the system?,System Information,,,
13,"What types of data are required for training, validating and testing the system?",System Information,,,
14,"Does the system require data to function in real-world operation? If so, what types of data are needed?",System Information,,,
15,"Does the system require structured, unstructured, or a combination of both data types?",System Information,,,
16,"What datasets were used to train, validate and test the system?",System Information,,,
17,How were the datasets obtained ?,System Information,,,
18,"Was any personal data collected for training, validation, or testing?",System Information,,,
19,"Are the datasets labeled or annotated? If so, who performed the labeling?",System Information,,,
20,What are the expected input types for the system?,System Information,,,
21,What are the expected output types of the system?,System Information,,,
22,Were any data-cleaning steps applied before using the datasets?,System Information,,,
23,How was the quality of the data ensured during collection and preprocessing?,System Information,,,
24,Are there any restrictions on the use of the datasets due to licensing or data protection laws?,System Information,,,
25,Does the dataset contain personally identifiable information ?,System Information,,,
26,"If personal data was used, was it anonymized or pseudonymized?",System Information,,,
27,Does your system provides Back-Up Data ?,System Information,,,
28,Were any steps taken to assess the representativeness of the training data?,System Information,,,
29,Were any external audits or reviews conducted on the dataset before use?,System Information,,,
30,Were any demographic groups underrepresented or overrepresented in the datasets?,System Information,,,
31,"Was any bias identified in the training, validation, or testing datasets?",System Information,,,
32,"If bias was detected, what steps were taken to mitigate it?",System Information,,,
33,Who will be most directly involved in using or operating the system? ,Generating stakeholders,,,
34, Who will have to interpret system outputs in order to make decisions?,Generating stakeholders,,,
35,Who will be involved in the system design and development? ,Generating stakeholders,,,
36, Who are the stakeholders for each intended use?,Generating stakeholders,,,
37,"Which demographic groups, especially marginalized groups, might be at risk of experiencing fairness harms?",Fairness Considerations,,,
38,How will the system be designed to minimize these harms?,Fairness Considerations,,,
39,Has an impact assessment been conducted to evaluate the potential discriminatory effects of the AI system?,Fairness Considerations,,,
40,Are there mechanisms in place to address any identified discriminatory effects? ,Fairness Considerations,,,
41,"Are the bias detection and mitigation strategies up-to-date? (Yes/No)
",Fairness Considerations,,,
42,"What kind of human intervention can be found in your AI system ensuring a human-in-the-loop, humanon-the-loop, or human-in-command approach?",Human intervention,,,
43,Is there any scenario where human intervention would not immediately be possible?,Human intervention,,,
44,How could someone misuse the system?,Potential impact of misuse,,,
45,"How would misuse impact stakeholders?
",Potential impact of misuse,,,
46,"Do the consequences of misuse differ for any marginalized groups?
",Potential impact of misuse,,,
47,Does your system function as a biometric categorization system (grouping individuals based on shared characteristics) or as a biometric identification system (uniquely identifying individuals),Biometric data,,,
48,"Assess whether your system deduces sensitive attributes (e.g. race, political opinions, sexual orientation) or if it categorises non-sensitive attributes (e.g. hair colour, eye colour).",Biometric data,,,
49,Could the system uphold or become a threat to human rights?,Potentional Harm,,,
50,Could the system result in a risk of physical or psychological injury?,Potentional Harm,,,
51,Does the system meet the definition of a Restricted Use?,Potentional Harm,,,
52,"What harms might this stakeholder experience if the system does not effectively solve the intended 
problem?",Potentional Harm,,,
53,"What harms might this stakeholder experience if the system is not subject to appropriate human oversight 
and control?",Potentional Harm,,,
54,"What harms might this stakeholder experience if they are unaware that they are interacting with an AI system 
when that system impersonates human interaction or generates or manipulates image, audio or video 
content that could falsely appear to be authentic? ",Potentional Harm,,,
55,"What risk management measures are adopted to address the known and foreseeable risks of high-risk AI systems to health, safety, or fundamental rights when used as intended?",Risk Managment,,,
56,"Is your AI system used in accordance with its intended purpose, and under conditions of reasonably foreseeable misuse?",Risk Managment,,,